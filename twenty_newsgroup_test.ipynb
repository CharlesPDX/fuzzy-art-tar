{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from preprocessing import get_tf_idf_twenty_newsgroup_corpus\n",
    "from fuzzy_artmap_module import FuzzyArtMap\n",
    "from fuzzy_artmap_module import complement_encode\n",
    "\n",
    "valid_vector = np.array([[1.0], [0.0]])\n",
    "invalid_vector = np.array([[0.0], [1.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus, categories, vectorizer = get_tf_idf_twenty_newsgroup_corpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_indexes = [4000, 4001]\n",
    "atheism_and_graphics = {index: category for index, category in categories.items() if (category == \"alt.atheism\" or category == \"comp.graphics\") and index not in seed_indexes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_document_indexes = random.sample(list(atheism_and_graphics.keys()), len(atheism_and_graphics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_input_and_output(doc_index, vector, relevant_category):\n",
    "    if categories[doc_index] == relevant_category:\n",
    "        output_value = valid_vector\n",
    "    else:\n",
    "        output_value = invalid_vector\n",
    "    \n",
    "    complement_encoded_input = complement_encode(vector.toarray().transpose())\n",
    "    return complement_encoded_input, output_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fuzzy_artmap = FuzzyArtMap(corpus.shape[1]*2, 1, rho_a_bar=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_category = \"alt.atheism\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iteration_count, document_index in enumerate(shuffled_document_indexes[:100]):\n",
    "    print(iteration_count)\n",
    "    input_vector, class_vector = get_test_input_and_output(document_index, corpus[document_index], relevant_category)\n",
    "    fuzzy_artmap.train(input_vector, class_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_counter = Counter({\"TP\": 0, \"TN\": 0, \"FP\": 0, \"FN\": 0})\n",
    "# predictions = []\n",
    "for document_index in shuffled_document_indexes[100:500]:\n",
    "    input_vector, class_vector = get_test_input_and_output(document_index, corpus[document_index], relevant_category)\n",
    "    prediction, membership_degree = fuzzy_artmap.predict(input_vector)\n",
    "    # if prediction[0][0]:\n",
    "    #     predictions.append((membership_degree, document_index, class_vector[0][0]))\n",
    "    # if prediction[0][0]:\n",
    "    #     print(f\"predicted: {prediction[0][0]} actual: {class_vector[0][0]} membership: {membership_degree} doc: {document_index}\")\n",
    "    # print(f\"predicted: {prediction[0][0]} actual: {class_vector[0][0]} membership: {membership_degree}\")\n",
    "    if class_vector[0][0]:\n",
    "        if prediction[0][0]:\n",
    "            update = {\"TP\": 1}\n",
    "        else:\n",
    "            update = {\"FN\": 1}\n",
    "    else:\n",
    "        if prediction[0][0]:\n",
    "            update = {\"FP\": 1}\n",
    "        else:\n",
    "            update = {\"TN\": 1}\n",
    "    accuracy_counter.update(update)\n",
    "print(accuracy_counter)\n",
    "# predictions.sort(key=lambda p: p[0])\n",
    "# print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_document(vectorizer, corpus, document_index):\n",
    "    features = vectorizer.get_feature_names_out()\n",
    "    for feature_index in corpus[document_index].indices:\n",
    "        print(features[feature_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_document(vectorizer, corpus, 13938)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1c7fd97181157154b62cb21d4934004d93b01e25a27fd6eef6c2f2e3a46eb491"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
